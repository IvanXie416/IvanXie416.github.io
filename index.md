---
layout: page
---

# About Me

<!-- <img src="ivan.png" class="floatpic"> -->

Here is **Yifan Xie (Ivan, 谢奕凡)**.<br>


I am now a Ph.D. student at [Tsinghua University](https://www.tsinghua.edu.cn/en/), under the supervision of Prof. [Wenbo Ding](https://ssr-group.net/index.html) and Prof. [Fuchun Sun](https://www.cs.tsinghua.edu.cn/csen/info/1312/4393.htm). 
Previously, I obtained my Master's degree from [Xi'an Jiaotong University](https://en.xjtu.edu.cn/) in 2025.
I am currently a research intern at [X Square Robot](https://www.x2robot.com/).

My research focuses on **Robotic Manipulation, Tactile Perception, 3D Vision and Affective Computing.**
Feel free to reach out for collaboration and discussion of research ideas (Email: ivanxie416[at]gmail.com).

<!-- ---

## Research Interests

- Robotic Manipulation
- Tactile Perception
- 3D Vision
- Affective Computing -->

---

## News and Updates

- **[2025.06]** Two papers are accepted by **[IROS 2025](https://iros25.org/)**.
- **[2025.06]** I begin my internship at **[X Square Robot](https://www.x2robot.com/)**.
- **[2025.06]** My master's thesis is awarded as the **Outstanding Master's Thesis of Xi'an Jiaotong University**.
- **[2025.06]** I obtain my master's degree from **Xi'an Jiaotong University**.
- **[2025.05]** Our paper **A Review of Human Emotion Synthesis Based on Generative Technology** is accepted by **[IEEE Transactions on Affective Computing](https://xplorestaging.ieee.org/xpl/RecentIssue.jsp?punumber=5165369)** (IF=9.6).
- **[2024.12]** Our paper **PointTalk: Audio-Driven Dynamic Lip Point Cloud for 3D Gaussian-based Talking Head Synthesis** is accepted by **[AAAI 2025](https://aaai.org/conference/aaai/aaai-25/)** (CCF-A).
- **[2024.10]** Our paper **Generative Technology for Human Emotion Recognition: A Scoping Review** is accepted by **[Information Fusion](https://www.sciencedirect.com/journal/information-fusion)** (IF=14.8).

<br>

<!-- --- -->

<!-- ## Selected Publications and Preprints

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv</div><img src='images/ivan.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<a href="https://www.techrxiv.org/users/836049/articles/1228135-human-motion-video-generation-a-survey" style="font-size: 22px; color: #483D8B; text-decoration: none">**Human Motion Video Generation: A Survey**</a><br>
<span style="font-size: 18px;">Haiwei Xue, **Xiangyang Luo**, Zhanghao Hu, Xin Zhang, Xunzhi Xiang, Yuqin Dai, Jianzhuang Liu, Minglei Li, Jian Yang, Fei Ma, Changpeng Yang, Zonghong Dai, Fei Richard Yu </span><br>
<span style="font-size: 18px;">[**Paper**](https://www.techrxiv.org/users/836049/articles/1228135-human-motion-video-generation-a-survey)</span> -->

<!-- <span style="font-size: 18px;">- This survey provides a comprehensive review of human motion video generation methods, covering the latest techniques, applications, and future directions.</span> -->

</div>
</div>



